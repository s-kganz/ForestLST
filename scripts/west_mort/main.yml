# This file defines a snakefile for creating the west_mort dataset. Note that this must be run from the
# CLI with the --configfile flag set.
if not "regions" in config:
    raise ValueError("Snakemake must be run with the --configfile flag set")
REGIONS = config["regions"]
DATA_IN=config["data_in"]
DATA_WORKING=config["data_working"]
OUTPUT=config["final_output"]
SURVEY_OUTPUT=config["survey_output"]
SRS=config["srs"]

YEARS=list(range(int(config["year_start"]), int(config["year_end"])+1))

import os
head, _ = os.path.split(config["final_output"])
os.makedirs(head, exist_ok=True)
os.makedirs(DATA_IN, exist_ok=True)
os.makedirs(DATA_WORKING, exist_ok=True)

rule all:
    input:
        OUTPUT

rule combine:
    input:
        os.path.join(DATA_WORKING, "terrain.nc"),
        os.path.join(DATA_WORKING, "forest_cover.tif"),
        expand(os.path.join(DATA_WORKING, "mtbs_rasters", "{y}.tif"), y=YEARS),
        #os.path.join(DATA_WORKING, "summer_vod.nc"),
        expand(os.path.join(DATA_WORKING, "daymet", "{y}.nc"), y=YEARS),
        expand(os.path.join(DATA_WORKING, "damage_rasters", "{y}.tif"), y=YEARS),
        os.path.join(DATA_WORKING, "genus_basal_area/abies.tif"),
        #os.path.join(DATA_WORKING, "genus_basal_area/picea.tif"),
        os.path.join(DATA_WORKING, "genus_basal_area/populus.tif"),
        os.path.join(DATA_WORKING, "genus_basal_area/pseudotsuga.tif"),
        os.path.join(DATA_WORKING, "genus_basal_area/tsuga.tif"),
        expand(os.path.join(DATA_WORKING, "gfw_damage", "{y}.tif"), y=YEARS)
    output:
        OUTPUT
    script:
        "combine_data.py"

rule download_ads:
    input:
    output:
        expand(os.path.join(DATA_IN, "ads/CONUS_Region{n}_AllYears.gdb/timestamps"), n=REGIONS)
    shell:
        "./scripts/west_mort/download_ads.sh {DATA_IN}"

rule download_mtbs:
    input:
    output:
        os.path.join(DATA_IN, "mtbs/mtbs_perims_DD.shp")
    shell:
        f"./scripts/west_mort/download_mtbs.sh {DATA_IN}"

rule download_vodca:
    input:
    output:
        temp(os.path.join(DATA_IN, "vodca/VODCA_X-band_1997-2018_v01.0.0.zip"))
    shell:
        f"./scripts/west_mort/download_vodca.sh {DATA_IN}"

rule process_vodca:
    input:
        os.path.join(DATA_WORKING, "template.tif"),
        os.path.join(DATA_IN, "vodca/VODCA_X-band_1997-2018_v01.0.0.zip")
    output:
        os.path.join(DATA_WORKING, "summer_vod.nc")
    script:
        "process_vodca.py"

rule download_nlcd:
    input:
    output:
        os.path.join(DATA_IN, "nlcd/nlcd_tcc_conus_2021_v2021-4.tif")
    shell:
        "./scripts/west_mort/download_nlcd.sh {DATA_IN}"

rule merge_ads:
    input:
        expand(os.path.join(DATA_IN, "ads/CONUS_Region{n}_AllYears.gdb/timestamps"), n=REGIONS)
    output:
        os.path.join(DATA_WORKING, "damage_merged.gdb/timestamps"),
        os.path.join(DATA_WORKING, "survey_merged.gdb/timestamps")
    run:
        # Snakemake automatically creates the .gdb folders, but this prevents gdal from making the dataset.
        # So we have to prepend the script with a rm -r to delete the directories.
        shell("rm -r {DATA_WORKING}/damage_merged.gdb {DATA_WORKING}/survey_merged.gdb") 
        shell("./scripts/west_mort/merge_ads_polygons.sh {SRS}")
        if SURVEY_OUTPUT: shell("cp -r {DATA_WORKING}/damage_merged.gdb {SURVEY_OUTPUT}")

rule burn_ads:
    input:
        os.path.join(DATA_WORKING, "damage_merged.gdb/timestamps"),
        os.path.join(DATA_WORKING, "survey_merged.gdb/timestamps"),
        os.path.join(DATA_IN, "nlcd/nlcd_tcc_conus_2021_v2021-4.tif")
    output:
        os.path.join(DATA_WORKING, "forest_cover.tif"),
        os.path.join(DATA_WORKING, "forest_mask.tif"),
        expand(os.path.join(DATA_WORKING, "damage_rasters", "{y}.tif"), y=YEARS)
    script:
        "burn_ads_polygons.py"

rule terrain:
    input:
        os.path.join(DATA_WORKING, "template.tif")
    output:
        os.path.join(DATA_WORKING, "terrain.nc")
    script:
        "download_terrain.py"

rule burn_mtbs:
    input: 
        os.path.join(DATA_IN, "mtbs/mtbs_perims_DD.shp"),
    output:
        expand(os.path.join(DATA_WORKING, "mtbs_rasters/{y}.tif"), y=YEARS)
    script:
        "burn_mtbs_polygons.py"

rule daymet:
    input:
        os.path.join(DATA_WORKING, "template.tif"),
    output:
        os.path.join(DATA_WORKING, "daymet", "{y}.nc")
    params:
        year="{y}"
    script:
        "download_daymet.py"

rule download_nidrm:
    input:
    output:
        os.path.join(DATA_IN, "nidrm/L48_BA.gdb/timestamps"),
        os.path.join(DATA_IN, "nidrm/L48_Totals.gdb/timestamps")
    shell:
        "rm -r data_in/nidrm/L48_BA.gdb data_in/nidrm/L48_Totals.gdb && ./scripts/west_mort/download_nidrm.sh {DATA_IN}"

rule coarsen_nidrm:
    input:
        os.path.join(DATA_IN, "nidrm/L48_BA.gdb/timestamps"),
        os.path.join(DATA_IN, "nidrm/L48_Totals.gdb/timestamps"),
        #os.path.join(DATA_WORKING, "forest_mask.tif")
    output:
        os.path.join(DATA_WORKING, "genus_basal_area/abies.tif"),
        #os.path.join(DATA_WORKING, "genus_basal_area/picea.tif"),
        os.path.join(DATA_WORKING, "genus_basal_area/populus.tif"),
        os.path.join(DATA_WORKING, "genus_basal_area/pseudotsuga.tif"),
        os.path.join(DATA_WORKING, "genus_basal_area/tsuga.tif")
    script:
        "coarsen_genus_ba.py"

rule coarsen_gfw:
    input:
    output:
        expand(os.path.join(DATA_WORKING, "gfw_damage", "{y}.tif"), y=YEARS)
    script:
        "coarsen_gfw.py"

rule template:
    input:
    output:
        os.path.join(DATA_WORKING, "template.tif")
    script:
        "make_template.py"